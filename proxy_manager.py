import requests
import random
import asyncio
from datetime import datetime, timedelta
import logging

class ProxyManager:
    def __init__(self):
        self.proxy_pool = []
        self.last_refresh = datetime.min
        self.logger = logging.getLogger("proxy_manager")
        self.proxy_score = {}
    
    async def fetch_proxies(self):
        """ä½¿ç”¨æ›´å¯é çš„ä»£ç†æº"""
        sources = [
            "https://proxylist.geonode.com/api/proxy-list?protocols=http&limit=200&country=US,GB,CA,DE",
            "https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=all",
            "https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt",
            "https://raw.githubusercontent.com/clarketm/proxy-list/master/proxy-list-raw.txt",
            "https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/http.txt"
        ]
        
        proxies = set()
        for url in sources:
            try:
                self.logger.info(f"è·å–ä»£ç†æº: {url}")
                response = requests.get(url, timeout=20)
                
                if "geonode" in url:
                    # å¤„ç† GeoNode çš„ JSON æ ¼å¼
                    data = response.json()
                    for item in data["data"]:
                        proxy = f"{item['ip']}:{item['port']}"
                        proxies.add(proxy)
                else:
                    # å¤„ç†æ–‡æœ¬æ ¼å¼
                    for line in response.text.splitlines():
                        proxy = line.strip()
                        if ":" in proxy and proxy not in proxies:
                            proxies.add(proxy)
            except Exception as e:
                self.logger.error(f"ä»£ç†æºè·å–å¤±è´¥ {url}: {str(e)}")
        
        return list(proxies)
    
    async def validate_proxy(self, proxy):
        """ä½¿ç”¨æ›´å¯é çš„éªŒè¯æ–¹æ³•"""
        test_urls = [
            "http://www.example.com",  # è½»é‡çº§é¡µé¢
            "http://www.google.com/gen_204",
            "http://www.cloudflare.com/cdn-cgi/trace"
        ]
        
        for url in test_urls:
            try:
                start_time = datetime.now()
                response = requests.get(
                    url,
                    proxies={"http": f"http://{proxy}", "https": f"http://{proxy}"},
                    timeout=10,
                    headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"}
                )
                if response.status_code in [200, 204]:
                    speed = (datetime.now() - start_time).total_seconds()
                    self.logger.info(f"âœ… ä»£ç†å¯ç”¨: {proxy} | é€Ÿåº¦: {speed:.2f}s")
                    return True, speed
            except Exception as e:
                continue
        
        self.logger.warning(f"âŒ ä»£ç†ä¸å¯ç”¨: {proxy}")
        return False, 10.0
    
    async def update_proxy_pool(self):
        self.logger.info("ğŸ”„ æ›´æ–°ä»£ç†æ± ...")
        raw_proxies = await self.fetch_proxies()
        valid_proxies = []
        
        # å¹¶è¡ŒéªŒè¯ä»£ç† (é™åˆ¶ä¸º50ä¸ª)
        tasks = [self.validate_proxy(proxy) for proxy in raw_proxies[:50]]
        results = await asyncio.gather(*tasks)
        
        for i, (is_valid, speed) in enumerate(results):
            if is_valid:
                proxy = raw_proxies[i]
                valid_proxies.append(proxy)
                # æ ¹æ®é€Ÿåº¦è¯„åˆ† (1-10)
                self.proxy_score[proxy] = max(1, min(10, int(10 - speed * 2)))
                self.logger.info(f"âœ… ä»£ç†å¯ç”¨: {proxy} | é€Ÿåº¦: {speed:.2f}s | è¯„åˆ†: {self.proxy_score[proxy]}")
        
        self.proxy_pool = valid_proxies
        self.last_refresh = datetime.now()
        self.logger.info(f"ä»£ç†æ± æ›´æ–°å®Œæˆ. å¯ç”¨ä»£ç†: {len(self.proxy_pool)}")
    
    async def keep_proxy_pool_updated(self):
        """å®šæœŸæ›´æ–°ä»£ç†æ± çš„åå°ä»»åŠ¡ï¼Œé¿å…é«˜å³°æ—¶æ®µæ›´æ–°"""
        while True:
            try:
                # æ¯15åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
                await asyncio.sleep(900)  # 15åˆ†é’Ÿ
                
                # è·å–å½“å‰æ—¶é—´
                current_hour = datetime.now().hour
                
                # åªåœ¨ä½å³°æ—¶æ®µæ›´æ–°ä»£ç†ï¼ˆå‡Œæ™¨2-6ç‚¹ï¼‰
                if 2 <= current_hour <= 6:
                    self.logger.info("ğŸŒ™ ä½å³°æ—¶æ®µæ›´æ–°ä»£ç†æ± ...")
                    await self.update_proxy_pool()
                else:
                    self.logger.info("â³ è·³è¿‡é«˜å³°æ—¶æ®µä»£ç†æ›´æ–°")
            except Exception as e:
                self.logger.error(f"ä»£ç†æ± æ›´æ–°å¤±è´¥: {str(e)}")
                await asyncio.sleep(300)  # å‡ºé”™åç­‰å¾…5åˆ†é’Ÿé‡è¯•
    
    async def get_best_proxy(self):
        """è·å–æœ€ä½³ä»£ç†ï¼Œè‡ªåŠ¨åˆ·æ–°æ± """
        # å¦‚æœè¶…è¿‡15åˆ†é’Ÿæ²¡æœ‰æ›´æ–°æˆ–ä»£ç†æ± ä¸ºç©ºï¼Œåˆ™æ›´æ–°ä»£ç†æ± 
        if (datetime.now() - self.last_refresh) > timedelta(minutes=15) or not self.proxy_pool:
            try:
                # å¿«é€Ÿæ›´æ–°ä»£ç†æ± ï¼ˆ30ç§’è¶…æ—¶ï¼‰
                await asyncio.wait_for(self.update_proxy_pool(), timeout=30)
            except asyncio.TimeoutError:
                self.logger.warning("ä»£ç†æ›´æ–°è¶…æ—¶ï¼Œä½¿ç”¨ç°æœ‰ä»£ç†æˆ–ç›´è¿")
        
        if not self.proxy_pool:
            return None
        
        # æ ¹æ®è¯„åˆ†åŠ æƒéšæœºé€‰æ‹©
        weighted_pool = []
        for proxy in self.proxy_pool:
            weight = self.proxy_score.get(proxy, 5)
            weighted_pool.extend([proxy] * weight)
        
        return random.choice(weighted_pool)
    
    def report_proxy_failure(self, proxy):
        """ä»£ç†å¤±è´¥å¤„ç†"""
        if proxy in self.proxy_score:
            self.proxy_score[proxy] = max(1, self.proxy_score[proxy] - 3)
            self.logger.warning(f"âš ï¸ ä»£ç†é™çº§: {proxy} | æ–°è¯„åˆ†: {self.proxy_score[proxy]}")
