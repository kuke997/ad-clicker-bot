import os
import asyncio
import json
import random
import logging
from datetime import datetime
from pathlib import Path
from proxy_manager import ProxyManager
from behavior_simulator import BehaviorSimulator
from playwright.async_api import async_playwright
from fastapi import FastAPI

# é…ç½®å‚æ•°
CLICKS_PER_MINUTE = 8
MIN_INTERVAL = 5  # ç§’
MAX_INTERVAL = 15  # ç§’
MAX_RETRIES = 3
NETWORK_ERROR_RETRY_DELAY = 10  # ç½‘ç»œé”™è¯¯é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,  # é™ä½æ—¥å¿—çº§åˆ«ä¸ºINFO
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
    ]
)

# åˆ›å»ºå…¨å±€è®°å½•å™¨
logger = logging.getLogger("ad-clicker-bot")

# å…¨å±€çŠ¶æ€å˜é‡
last_successful_click = datetime.now()
is_running = False
task = None
proxy_manager = None  # ä»£ç†ç®¡ç†å™¨å…¨å±€å®ä¾‹

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI()

def get_random_user_agent():
    """è¿”å›éšæœºçš„ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²"""
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/114.0",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 16_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.4 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (Linux; Android 13; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Mobile Safari/537.36"
    ]
    return random.choice(user_agents)

async def self_keep_alive():
    """è‡ªä¿æ´»æœºåˆ¶ - å½“æ£€æµ‹åˆ°é•¿æ—¶é—´æ— æˆåŠŸç‚¹å‡»æ—¶é‡ç½®çŠ¶æ€"""
    global last_successful_click, proxy_manager
    
    time_since_last_success = (datetime.now() - last_successful_click).total_seconds()
    if time_since_last_success > 1800:  # 30åˆ†é’Ÿæ— æˆåŠŸç‚¹å‡»
        logger.warning("âš ï¸ é•¿æ—¶é—´æ— æˆåŠŸç‚¹å‡»ï¼Œé‡ç½®çŠ¶æ€...")
        last_successful_click = datetime.now()
        
        # é‡ç½®ä»£ç†ç®¡ç†å™¨
        if proxy_manager:
            # é‡æ–°åˆ›å»ºä»£ç†ç®¡ç†å™¨å¹¶æ›´æ–°ä»£ç†æ± 
            proxy_manager = ProxyManager()
            try:
                await proxy_manager.update_proxy_pool()
                logger.info("ğŸ”„ ä»£ç†æ± å·²é‡ç½®")
            except Exception as e:
                logger.error(f"é‡ç½®ä»£ç†æ± å¤±è´¥: {str(e)}")
        else:
            logger.error("ä»£ç†ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•é‡ç½®")
        
        return True
    return False

async def simulate_ad_browse(page):
    """åœ¨å¹¿å‘Šé¡µé¢æ¨¡æ‹Ÿ5ç§’éšæœºæµè§ˆå’Œæ»‘åŠ¨"""
    logger.info("ğŸ”„ è¿›å…¥å¹¿å‘Šé¡µé¢ï¼Œæ¨¡æ‹Ÿ5ç§’éšæœºæµè§ˆ...")
    
    start_time = datetime.now()
    while (datetime.now() - start_time).total_seconds() < 5:
        # éšæœºæ»šåŠ¨
        scroll_amount = random.randint(100, 500)
        scroll_direction = random.choice([-1, 1])  # éšæœºå‘ä¸Šæˆ–å‘ä¸‹æ»šåŠ¨
        await page.evaluate(f"window.scrollBy(0, {scroll_amount * scroll_direction})")
        
        # éšæœºç­‰å¾…
        wait_time = random.uniform(0.5, 1.5)
        await asyncio.sleep(wait_time)
        
        # éšæœºç‚¹å‡»é¡µé¢ä¸Šçš„å…ƒç´ ï¼ˆéå¹¿å‘Šï¼‰
        try:
            elements = await page.query_selector_all("a, button, div")
            if elements:
                element = random.choice(elements)
                await element.click(delay=random.randint(50, 250))
                logger.debug("ğŸ–±ï¸ éšæœºç‚¹å‡»é¡µé¢å…ƒç´ ")
        except Exception:
            pass  # å¿½ç•¥ç‚¹å‡»é”™è¯¯
    
    logger.info("âœ… å¹¿å‘Šæµè§ˆå®Œæˆï¼Œè¿”å›ä¸»é¡µé¢")

async def click_ads(playwright, url, selector, target, proxy=None):
    """æ‰§è¡Œå¹¿å‘Šç‚¹å‡»æ“ä½œï¼Œæ”¯æŒæ—¶é—´æ•æ„Ÿå’Œç‚¹å‡»æ·±åº¦åŠŸèƒ½"""
    global last_successful_click
    
    browser = None
    try:
        # æ£€æŸ¥Chromiumæ˜¯å¦å­˜åœ¨
        chromium_path = Path("/ms-playwright/chromium/chrome-linux/chrome")
        if not chromium_path.exists():
            logger.error(f"âŒ Chromium not found at {chromium_path}")
            # å°è¯•é‡æ–°å®‰è£…
            logger.warning("âš ï¸ Attempting to reinstall Chromium...")
            os.system("PLAYWRIGHT_BROWSERS_PATH=/ms-playwright npx playwright install chromium --with-deps")
            if not chromium_path.exists():
                logger.error("âŒ Failed to reinstall Chromium")
                return False
        
        logger.info(f"ğŸŒ è®¿é—®ç›®æ ‡: {url} | é€‰æ‹©å™¨: {selector} | å¹¿å‘Šä½: {target.get('name', 'æœªçŸ¥')}")
        
        # é…ç½®æµè§ˆå™¨é€‰é¡¹
        launch_options = {
            "headless": True,
            "args": [
                "--disable-blink-features=AutomationControlled",
                "--disable-infobars",
                "--no-sandbox",
                "--disable-dev-shm-usage",  # è§£å†³Dockerå†…å­˜é—®é¢˜
                "--single-process",         # å‡å°‘èµ„æºå ç”¨
                f"--user-agent={get_random_user_agent()}",
                # æ·»åŠ GPUç¦ç”¨å‚æ•°
                "--disable-gpu",
                "--disable-software-rasterizer",
                "--disable-gl-drawing-for-tests",
                "--disable-breakpad",
                "--disable-setuid-sandbox",
                "--no-zygote",
                "--ignore-gpu-blocklist",
                "--disable-gpu-early-init",
                "--disable-gpu-sandbox",
                "--enable-webgl",
                "--use-gl=swiftshader",
                "--use-angle=swiftshader"
            ],
            # æŒ‡å®šChromiumå¯æ‰§è¡Œè·¯å¾„
            "executable_path": "/ms-playwright/chromium/chrome-linux/chrome"
        }
        
        # å¦‚æœæä¾›äº†ä»£ç†ï¼Œæ·»åŠ åˆ°å¯åŠ¨é€‰é¡¹
        if proxy:
            launch_options["proxy"] = {"server": f"http://{proxy}"}
        
        # å¯åŠ¨æµè§ˆå™¨
        logger.info("ğŸš€ å¯åŠ¨Chromiumæµè§ˆå™¨...")
        browser = await playwright.chromium.launch(**launch_options)
        
        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
        context = await browser.new_context(
            viewport={'width': 1280, 'height': 720},
            locale='en-US',
            # ç¦ç”¨WebDriveræ£€æµ‹
            bypass_csp=True
        )
        
        # åæ£€æµ‹æªæ–½
        await context.add_init_script("""
            delete navigator.__proto__.webdriver;
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            window.chrome = { runtime: {} };
        """)
        
        page = await context.new_page()
        
        # è®¿é—®ç›®æ ‡é¡µé¢ - å¢åŠ é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
        use_direct_connection = False
        navigation_attempts = 0
        max_navigation_attempts = 3
        navigation_success = False
        
        while not navigation_success and navigation_attempts < max_navigation_attempts:
            try:
                logger.info(f"ğŸ§­ å¯¼èˆªåˆ°: {url} (å°è¯• {navigation_attempts+1}/{max_navigation_attempts})")
                await page.goto(url, timeout=60000, wait_until="networkidle")
                logger.info(f"âœ… é¡µé¢åŠ è½½æˆåŠŸ")
                navigation_success = True
            except Exception as e:
                navigation_attempts += 1
                error_str = str(e)
                
                # å¦‚æœæ˜¯ä»£ç†é—®é¢˜ï¼Œå°è¯•ä¸ä½¿ç”¨ä»£ç†
                if "ERR_TUNNEL_CONNECTION_FAILED" in error_str or "ERR_PROXY_CONNECTION_FAILED" in error_str:
                    logger.warning(f"âš ï¸ ä»£ç†è¿æ¥å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¿æ¥...")
                    await browser.close()
                    
                    # é‡æ–°å¯åŠ¨æµè§ˆå™¨ä¸ä½¿ç”¨ä»£ç†
                    if "proxy" in launch_options:
                        del launch_options["proxy"]
                    
                    browser = await playwright.chromium.launch(**launch_options)
                    context = await browser.new_context(
                        viewport={'width': 1280, 'height': 720},
                        locale='en-US',
                        bypass_csp=True
                    )
                    await context.add_init_script("""
                        delete navigator.__proto__.webdriver;
                        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                        window.chrome = { runtime: {} };
                    """)
                    page = await context.new_page()
                    
                    logger.info(f"ğŸ§­ ç›´æ¥å¯¼èˆªåˆ°: {url}")
                    await page.goto(url, timeout=60000, wait_until="networkidle")
                    logger.info(f"âœ… é¡µé¢åŠ è½½æˆåŠŸ")
                    use_direct_connection = True
                    navigation_success = True
                # å¤„ç†è¿æ¥é‡ç½®é”™è¯¯
                elif "ERR_CONNECTION_RESET" in error_str or "ERR_EMPTY_RESPONSE" in error_str:
                    logger.warning(f"âš ï¸ ç½‘ç»œé”™è¯¯: {error_str} (å°è¯• {navigation_attempts}/{max_navigation_attempts})")
                    if navigation_attempts < max_navigation_attempts:
                        wait_time = NETWORK_ERROR_RETRY_DELAY * navigation_attempts
                        logger.info(f"â±ï¸ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(f"âŒ å¯¼èˆªå¤±è´¥: {error_str}")
                        return False
                # å¤„ç†å…¶ä»–ç½‘ç»œé”™è¯¯
                elif "net::" in error_str:
                    logger.warning(f"âš ï¸ ç½‘ç»œé”™è¯¯: {error_str} (å°è¯• {navigation_attempts}/{max_navigation_attempts})")
                    if navigation_attempts < max_navigation_attempts:
                        wait_time = NETWORK_ERROR_RETRY_DELAY * navigation_attempts
                        logger.info(f"â±ï¸ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(f"âŒ å¯¼èˆªå¤±è´¥: {error_str}")
                        return False
                else:
                    logger.error(f"âŒ å¯¼èˆªå¤±è´¥: {error_str}")
                    return False
        
        if not navigation_success:
            logger.error("âŒ å¯¼èˆªå¤±è´¥ï¼Œæ”¾å¼ƒå°è¯•")
            return False
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        await asyncio.sleep(random.uniform(2, 4))
        
        # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
        logger.info("ğŸ§  æ¨¡æ‹Ÿäººç±»è¡Œä¸º...")
        simulator = BehaviorSimulator(page)
        await simulator.simulate_behavior()
        
        # ======== å¹¿å‘Šç‚¹å‡»æ·±åº¦åŠŸèƒ½å®ç° ========
        click_depth_config = target.get("click_depth", {})
        
        # ç¡®å®šç‚¹å‡»æ¬¡æ•°
        if isinstance(click_depth_config, int):
            click_count = click_depth_config
        elif isinstance(click_depth_config, dict) and "min" in click_depth_config and "max" in click_depth_config:
            click_count = random.randint(click_depth_config["min"], click_depth_config["max"])
        else:
            click_count = 1
        
        # ç¡®å®šå¯ç‚¹å‡»å…ƒç´ ç±»å‹
        if isinstance(click_depth_config, dict):
            allowed_elements = click_depth_config.get("elements", ["a", "button", "div"])
        else:
            allowed_elements = ["a", "button", "div"]
        
        clickable_selector = f"{selector} {','.join(allowed_elements)}"
        
        logger.info(f"ğŸ¯ ç‚¹å‡»æ·±åº¦: {click_count}æ¬¡ | å…ƒç´ é€‰æ‹©å™¨: {clickable_selector}")
        
        # æ‰§è¡Œå¤šæ¬¡ç‚¹å‡»
        for i in range(click_count):
            # ç­‰å¾…å…ƒç´ å¯èƒ½å‡ºç°
            try:
                await page.wait_for_selector(clickable_selector, timeout=5000, state="attached")
            except Exception as e:
                logger.warning(f"â³ ç­‰å¾…å…ƒç´ è¶…æ—¶: {clickable_selector}")
            
            # æŸ¥æ‰¾æ‰€æœ‰å¯ç‚¹å‡»å…ƒç´ 
            elements = await page.query_selector_all(clickable_selector)
            
            if not elements:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°å¯ç‚¹å‡»å…ƒç´ : {clickable_selector}")
                # å°è¯•æˆªå›¾ç”¨äºè°ƒè¯•
                try:
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    await page.screenshot(path=f"screenshot_error_{timestamp}.png")
                    logger.info(f"ğŸ“¸ å·²ä¿å­˜é”™è¯¯æˆªå›¾: screenshot_error_{timestamp}.png")
                except Exception as e:
                    logger.error(f"æˆªå›¾å¤±è´¥: {str(e)}")
                break
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªå…ƒç´ ç‚¹å‡»
            element = random.choice(elements)
            
            # é«˜äº®å…ƒç´ ç”¨äºè°ƒè¯•
            try:
                await element.evaluate("el => el.style.border = '2px solid red'")
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•é«˜äº®å…ƒç´ : {str(e)}")
            
            # è®°å½•ç‚¹å‡»å‰çš„URL
            original_url = page.url
            logger.info(f"ğŸ“Œ ç‚¹å‡»å‰URL: {original_url}")
            
            # ç‚¹å‡»å…ƒç´ 
            try:
                # ä½¿ç”¨æ›´å¯é çš„ç‚¹å‡»æ–¹æ³•
                await element.scroll_into_view_if_needed()
                await element.click(delay=random.randint(100, 300))
                logger.info(f"ğŸ–±ï¸ âœ… æ·±åº¦ç‚¹å‡» {i+1}/{click_count} æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ ç‚¹å‡»å¤±è´¥: {str(e)}")
                # å°è¯•ä½¿ç”¨å…¶ä»–æ–¹å¼ç‚¹å‡»
                try:
                    await element.dispatch_event("click")
                    logger.info(f"ğŸ–±ï¸ âœ… å¤‡é€‰ç‚¹å‡»æ–¹å¼æˆåŠŸ")
                except Exception as e2:
                    logger.error(f"âŒ å¤‡é€‰ç‚¹å‡»æ–¹å¼ä¹Ÿå¤±è´¥: {str(e2)}")
                    break
            
            # === æ–°å¢åŠŸèƒ½ï¼šå¹¿å‘Šé¡µé¢æµè§ˆ ===
            try:
                logger.info("ğŸ” å¼€å§‹æ£€æµ‹å¹¿å‘Šé¡µé¢...")
                ad_page = None
                ad_page_type = "unknown"
                
                # 1. ç­‰å¾…ä¸€æ®µæ—¶é—´è®©é¡µé¢ååº”
                logger.info("â±ï¸ ç­‰å¾…2ç§’è®©é¡µé¢ååº”...")
                await asyncio.sleep(2)
                
                # 2. æ£€æŸ¥URLæ˜¯å¦å˜åŒ–
                current_url = page.url
                logger.info(f"ğŸ“Œ å½“å‰URL: {current_url}")
                
                if current_url != original_url:
                    logger.info(f"ğŸ”— URLå˜åŒ–: {original_url} -> {current_url}")
                    ad_page = page
                    ad_page_type = "url_change"
                else:
                    logger.info("ğŸ”— URLæœªå˜åŒ–")
                
                # 3. æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ ‡ç­¾é¡µ
                pages = context.pages
                if len(pages) > 1:
                    logger.info(f"ğŸªŸ æ£€æµ‹åˆ° {len(pages)-1} ä¸ªæ–°æ ‡ç­¾é¡µ")
                    for p in pages:
                        if p != page:
                            logger.info(f"  - æ–°æ ‡ç­¾é¡µURL: {p.url}")
                            ad_page = p
                            ad_page_type = "popup"
                            break
                
                # 4. æ£€æŸ¥é¡µé¢å†…å®¹å˜åŒ–ï¼ˆDOMå˜åŒ–ï¼‰
                if not ad_page:
                    try:
                        # æ£€æŸ¥é¡µé¢æ ‡é¢˜æˆ–ä¸»è¦å†…å®¹åŒºåŸŸæ˜¯å¦å˜åŒ–
                        new_title = await page.title()
                        logger.info(f"ğŸ“ å½“å‰æ ‡é¢˜: {new_title}")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å¹¿å‘Šç›¸å…³å…ƒç´ å‡ºç°
                        ad_indicators = await page.query_selector_all(
                            ".ad, .advertisement, .promo, .banner, .modal, .popup"
                        )
                        if ad_indicators:
                            logger.info(f"ğŸ” æ£€æµ‹åˆ° {len(ad_indicators)} ä¸ªå¹¿å‘ŠæŒ‡ç¤ºå™¨å…ƒç´ ")
                            ad_page = page
                            ad_page_type = "ad_element"
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ£€æŸ¥é¡µé¢å†…å®¹å˜åŒ–å¤±è´¥: {str(e)}")
                
                # 5. å¦‚æœæ£€æµ‹åˆ°å¹¿å‘Šé¡µé¢ï¼Œè¿›è¡Œæµè§ˆ
                if ad_page:
                    logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å¹¿å‘Šé¡µé¢ ({ad_page_type})")
                    
                    # ç¡®ä¿åˆ‡æ¢åˆ°å¹¿å‘Šé¡µé¢
                    if ad_page != page:
                        await ad_page.bring_to_front()
                    
                    # ç­‰å¾…å¹¿å‘Šé¡µé¢åŠ è½½
                    try:
                        logger.info("â±ï¸ ç­‰å¾…å¹¿å‘Šé¡µé¢åŠ è½½...")
                        await ad_page.wait_for_load_state("networkidle", timeout=10000)
                        logger.info("âœ… å¹¿å‘Šé¡µé¢åŠ è½½å®Œæˆ")
                    except Exception as e:
                        logger.warning(f"âš ï¸ å¹¿å‘Šé¡µé¢åŠ è½½è¶…æ—¶: {str(e)}")
                    
                    # æ¨¡æ‹Ÿæµè§ˆè¡Œä¸º
                    await simulate_ad_browse(ad_page)
                    
                    # å…³é—­æ–°æ ‡ç­¾é¡µæˆ–è¿”å›åŸå§‹é¡µé¢
                    if ad_page != page:
                        logger.info("ğŸ”’ å…³é—­å¹¿å‘Šæ ‡ç­¾é¡µ...")
                        await ad_page.close()
                        await page.bring_to_front()  # åˆ‡æ¢å›åŸå§‹é¡µé¢
                    else:
                        # è¿”å›åŸå§‹é¡µé¢
                        logger.info("â†©ï¸ å°è¯•è¿”å›åŸå§‹é¡µé¢...")
                        try:
                            await page.go_back()
                            await page.wait_for_load_state("networkidle", timeout=60000)
                            logger.info("âœ… å·²è¿”å›åŸå§‹é¡µé¢")
                        except Exception as e:
                            logger.error(f"âŒ è¿”å›åŸå§‹é¡µé¢å¤±è´¥: {str(e)}")
                else:
                    logger.info("â±ï¸ æœªæ£€æµ‹åˆ°å¹¿å‘Šé¡µé¢è·³è½¬")
            except Exception as e:
                logger.error(f"âš ï¸ å¹¿å‘Šæµè§ˆå‡ºé”™: {str(e)}")
                # å°è¯•è¿”å›åŸå§‹é¡µé¢
                try:
                    if page.url != original_url:
                        await page.go_back()
                        await page.wait_for_load_state("networkidle", timeout=60000)
                except Exception:
                    pass
            
            # ç‚¹å‡»åéšæœºç­‰å¾…
            wait_time = random.uniform(0.5, 2.5)
            logger.info(f"â±ï¸ ç­‰å¾… {wait_time:.1f}ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡ç‚¹å‡»")
            await asyncio.sleep(wait_time)
        
        # æ›´æ–°æœ€åæˆåŠŸæ—¶é—´
        last_successful_click = datetime.now()
        
        # è¿”å›è¿æ¥æ–¹å¼ç”¨äºç»Ÿè®¡
        return "direct" if use_direct_connection else "proxy"
    except Exception as e:
        logger.error(f"âŒ ç‚¹å‡»å¤±è´¥: {str(e)}")
        # æ·»åŠ è¯¦ç»†é”™è¯¯æ—¥å¿—
        import traceback
        logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return False
    finally:
        if browser:
            try:
                await browser.close()
            except Exception as e:
                logger.warning(f"âš ï¸ å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {str(e)}")

# å…¶ä»–å‡½æ•°ä¿æŒä¸å˜ï¼ˆshould_skip_target, clicker_task, ç­‰ï¼‰
# ... [ä¿æŒä¸å˜çš„éƒ¨åˆ†ä»£ç ] ...

if __name__ == "__main__":
    # æœ¬åœ°è¿è¡Œå…¥å£
    logger.info("ğŸš€ å¯åŠ¨å¹¿å‘Šç‚¹å‡»æœºå™¨äºº...")
    asyncio.run(clicker_task())
